---
layout: inner
position: left
title: 'Hierarchical XAI systems for RL in Autonomous Vehicles'
date: 2019-01-01 14:15:00
categories: development
type: related
tags: Hierarchical-RL Python DQN
featured_image: 'img/posts/HRL/hrl.png'
project_link: 'https://github.com/notanymike/HRL'
button_icon: 'github'
button_text: 'Visit Project'
lead_text: 'A digital music player built using AngularJS'
---

# Hierarchical XAI systems for RL in Autonomous Vehicles

MSc Thesis / University of Edinburgh

In general, a Hierarchical Reinforcement Learning is a group of RL models organised in a hierarchy (or a tree if we ignore the raw actions). Every model is specialised in certain actions, and there is one model which takes care of solving the main task, usually called the “controller”. Given the hierarchy organisation, every model in a higher level uses some of the policies (or models) in lower levels to accomplish its specialised task.

Take for example this hierarchy (see figure 1) to drive a car in a simplified environment, here the policy “Avoid Obstacle” can make use of the sub-policies “Change Lane” or “Stay in Lane” to accomplish it goal. At the end, every policy uses whether a sub-policy or uses directly the raw actions of the agent, in this case accelerate, break, turn left, right or do nothing.

![Hierarchy](/site/img/posts/HRL/Hierarchy.png)

There are several benefits of using HRL. The most important is safety. Achieve safe systems for real life deployment is a challenge in AI. In the case of self-driving car (SDV), an error can have catastrophic results. Therefore, being able to decide if we should trust in a system is a priority. The main idea of the thesis is explor HRL models, because it can give an explanation of the behaviour that is accepted by the human reviewer when the behaviour is expected or successful. HRL allow us to divide the high-level policy and track with more details where a failure might have originated. By building a set of forward models locally for each policy, the XAI system is able to recognise where in the chain of policies the behaviour has not been the expected one.