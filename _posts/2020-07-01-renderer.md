---
layout: inner
title: 'A quick review of Differentiable Renderers'
date: 2020-07-08 14:15:00
categories: development
type: project
tags: Maths Differentiable-renderers SoftRas
featured_image: '/img/posts/renderer/softras.gif'
comments: true
lead_text: 'A quick review of Differentiable Renderers, more exactly a dive deep into SoftRas and a line-to-line understanding of the model'


---

# A "quick" review of Differentiable Renderers

More exactly Soft Rasterizer: A Differentiable Renderer for Image-based 3D Reasoning (paper [here](https://arxiv.org/abs/1904.01786)). The code commented is available [here](https://github.com/kopernikusai/SoftDepth/tree/comments).

<br/>
## General overview of model

The model goes through 3 steps. The last one is the soft rasterizer (in which we are interested). The order of the steps are

1. Lighting: Set the correct light effects on the faces/vertices depending on the light model. Here we modify the color of each vertex/face depending on the light model.
2. Transformation: Transforms the objects to the perspective of the camera and projects it to the image frame.
   1. Rotation happens in `look_at.py`.
   2. Projection happens in `perspective.py` or in `orthogonal.py` for each case .
3. Soft rasterization:
   1. Detailed explanation below.




This are some of the results

![softras](/img/posts/renderer/softras.gif)

## Soft rasterization

Rasterization is the process of figuring out which faces are not occluded for each pixel and render that color. In this paper even if the face is ocluded will have an effect in the pixel (that is why it is called soft-rasterization). In general terms the rasterization algorithm (`forward_soft_rasterize`) has two parts:

The function `forward_soft_rasterize`  launches:

* First: `forward_soft_rasterize_inv_cuda`: This runs `((batch_size * num_faces - 1) / threads +1)` blocks of 512 threads. It calculates the barycentric coordinates, $$FF^T$$ and if the face has any obstuse angle.
* Second it launches `forward_soft_rasterize_cuda_kernel`:  This runs in parallel for every pixel for every image in the batch with 512 threads.
  * For each pixel we loop all faces.

One of the outcomes of `forward_soft_rasterize_inv_cuda `is populating `faces_info`, which contains the face inverse, face symetric matrix and the which angle of face is obtuse.

- Each face has 3 points and each point has 3 coordinates: a total of 9
- Face inverse has 9 spaces (squared matrix)
- Face sym has 9 spaces (squared matrix)
- Face obt has 3 spaces (for each angle of the face (triangle))

  

The whole rasterization problem translate into findind the color for each pixel based on depth of each face.


<br/>
## How to generate pixel colors

The algorithm here is a bit harder to understand. It does not follow the exact same equations in the paper but the result is the same. 

The main equation to agregate the colors from **all** (mesh-) faces into each individual pixels is described by


$$
I_i = \sum_jw_j^iC_jÃ® + w_b^iC_b \hspace{1cm} \text{ with } \hspace{1cm} w_j^i = \frac{D_j^i\exp(z_j^i/\gamma)}{\sum_kD_k^i\exp (z_k^i/\gamma) + \exp(\epsilon/\gamma)}
$$


Where 


$$
D_j^i = \text{sigmoid}\left( \delta_j^i\frac{d^2(i,j)}{\sigma}\right) \hspace{1cm} \text{with } \hspace{1cm} \delta_j^i = \delta(i,j) \text{ and } \delta \text{ as described above.}
$$


for the $$i$$-th pixel and the $$j$$-th face. 

The $$w_j^i$$ weights the color for each face for this pixel by how far away (in $$x$$ and $$y$$) the pixel is to the face (by using $$D_j^i(d^2(i,j),\cdot)$$) (***which can be significantly improved - read notes***) and by how far away (depth in $$z$$) the face is with respect to the other faces for this pixel (closer faces will get more relative importance and far away faces) (by using $$\exp(z_j^i / \gamma)$$).

The exact algorithm they use is described below. This algorithm only describes the default approach, that means using "barycentric" distance, and soft asignment for colors and opacity.



1. For each pixel $$i$$ do:
   1. Calculate $$z$$:  $$z$$  is the inverse normalized depth.
   2. Intialize `softmax_sum` as $$\text{sm}_\text{sum} =  \exp (\epsilon / \gamma)$$
   3. initialize `soft_color` as $$c=\text{bg} \times \text{sm}_\text{sum}$$ with $$\text{bg}$$ as a tuple with the background with zero opacity.
   4. Initialize `softmax_max`as $$\text{sm}_\text{max} = \epsilon$$
   5. For each face $$j$$ do: 
      1. Initialize `soft_fragment` called $$D_j^i$$ in the paper as $$D_j^i = 1/\left[1+\exp\left(-d^2(i,j)/\sigma\right)\right]$$.
      2. Intialize `exp_delta_zp` equal to 1, that is $$ z_\Delta = 1$$ 
      3. if $$z > \text{sm}_\text{max}$$ then:
         1. set $$z_\Delta = \exp\left( (\text{sm}_\text{max} - z) / \gamma \right)$$
         2. set $$\text{sm}_\max = z$$.
      4. Set $$\text{sm}_\text{sum} = z_\Delta \cdot \text{sm}_\text{sum} + \exp\left( \frac{z - \text{sm}_\max}{\gamma} \right) \cdot D_j^i$$
      5. Get the color for this face $$c_k$$.  
      6. Set $$c = z_\Delta \cdot c + \exp\left( \frac{z-\text{sm}_\max} {\gamma} \right) D_j^i c_k$$
   6. Normalize the color by $$\text{sm}_\text{sum}$$, that is $$c = c/\text{sm}_\text{sum}$$.

   

This change in the equations makes the final sum of all the components (i.e. the denominator of $$w_i$$ or $$\text{sm}_\text{sum}$$) become


$$
\text{sm}_\text{sum} = \exp\left(\frac {\epsilon - \text{sm}_\max}  \gamma \right) + \sum_i\exp\left( \frac{z_i - \text{sm}_\max }{\gamma}\right) D_j^i
$$


In this way each values of the first exponentials in the sum in the denominator is clipped to values between $$\left[-\min(\max(z_i), 1),0\right]$$. Which does not change anything due to the fact the we can factorise $$\exp(- \text{sm}_\max)$$ from the denominator and from the numerator, so both cancel each out and the result is the same as in the paper. 

The only difference is that during execution the values stay between $$[-\max z_i, 0]$$ which helps to avoid overflowing. Doing some iterations is very useful to understand the final form of the denomintor and why we can just factorise the max term.


<br/>
## Complementary functions for the rasterization process

The following sections are useful to understand specific functions of the whole rasterization process

### How to represent barycentric coordinates

The simpliest way to understand barycentric coordinates are with masses, the barycentric coordinates are the correponding weight (mass) in each edge of the face (in this case) which will make the point of gravity be at the same euclidian point we are trying to represent.



$$
\pmb p_i = U_i \pmb \lambda_i, \hspace{1cm} \text{with } \pmb \lambda_i = \left[ \begin{matrix} \lambda_1\\ \lambda_2 \\ \lambda_3\end{matrix} \right], U_i = \left[ \begin{matrix}x_1 & x_2 & x_3 \\ y_1 & y_2 & y_3 \\ 1 & 1 & 1 \end{matrix} \right], \pmb p_i = \left[ \begin{matrix}x\\y\\1\end{matrix}\right]
$$



The last row of $$U_i$$ takes care of assuring that $$\sum \lambda_j = 1$$. 

Therefore if we want to convert from euclidian coordinates to barycentric coordinates the equation becomes


$$
\pmb \lambda_i = U^{-1}\pmb p_i
$$




<br/>
### Definition of "Barycentric Distance"

The definition of barycentric distance for the $i$-th pixel and $j$-th face is  


$$
d_\text{bary}(i,j) = \min(\lambda_1, \lambda_2, \lambda_3)
$$



where $$\lambda_i$$ are the barycentric coordinates.


<br/>
### How to find euclidian distance using barycentric coordinates

Defining $$\pmb p = (x,y)$$ as any point (inside or outiside the triangle) and $$\pmb b = (u,v,w) $$ as the barycentric coordinates of $$\pmb p$$ and $$\pmb t$$ as the perpendicular point of $$\pmb b$$ to the closest edge of the triangle, then we can define the distance as


$$
d(\pmb p, T) = \delta||U(\pmb t- \pmb b)|| \hspace{1cm} \text{with } \hspace{1cm}     \delta = \begin{cases} +1 & \pmb x \text{ is inside the triangle }\\ -1 & \pmb x \text{ is outside the triangle} \end{cases}
$$


We can simplify looking for the closest edge of the triangle by looping through the 3 edges and getting the minimum distance. The only unknown is how to calculate $$\pmb t$$ using barycentric coordinates. Questions are asked in math exchange ([here](https://math.stackexchange.com/questions/3748903/closest-point-to-triangle-edge-with-barycentric-coordinates)) and in the original repo ([here](https://github.com/ShichenLiu/SoftRas/issues/55)). So far no answer.


<br/>
## Questions

Some questions that can rise while understing the code

1. Why we only work with 2d coords during the rasterization process? Because points are alredy projected.
2. Why do we calculate $$F F^T$$. Because it gives us useful information, for example the element (1,1) will be the squared lenght of the first vector. Or it is used to check how far away a point is from a triangle
3. Why do we do `\.\.\.\&faces[bn * nf * 9] - 9;`? Shouldn't it start from 0 so there is no need for the `-9`? yes, we only use `-9`  to make the code more readable in the next big loop (it add `9`  every step, including the zero step)
4. Why the barycentric distance is the min of the barycentric weights (coords)? They say that just works, but isn't it discontinous?
5. Why $$x+y+z = 0$$? It cannot happen (like in the code) that `w[0] + w[1] + w[2] = 0` (the code has a typo) but what can happen is $$x+y+z=0$$ and that is because if $$(x,y,z) = \vec{PQ}$$  (i.e. $$\vec{PQ} = Q-P$$) if $$P$$ and $$Q$$ are inside the triangle and normalised.
6. What is the structure of `texture`? It is $$[\text{batch, face_number, resolution, 3}]$$

   

<br/>
## Some useful resources
* This is a good intro to CUDA memory management: [https://developer.nvidia.com/blog/even-easier-introduction-cuda/](https://developer.nvidia.com/blog/even-easier-introduction-cuda/)
* And this is a perfect intro of how to create function in pytorch using CUDA: [https://pytorch.org/tutorials/advanced/cpp_extension.html](https://pytorch.org/tutorials/advanced/cpp_extension.html)